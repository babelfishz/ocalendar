{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "orchid-gd.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/babelfishz/ocalendar/blob/master/orchid_gd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wI_44CTJCBgF",
        "colab_type": "code",
        "outputId": "7e0605c2-e37b-4cc0-c791-26e8991e0a32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n",
            "gdrive\tsample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwZ3mkPkdMsT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tf-nightly"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TM5xTC643YiF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install --upgrade tensorflow\n",
        "#!pip install tf-nightly"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqixy4bFqAq9",
        "colab_type": "code",
        "outputId": "aa024b37-4705-4351-bfcc-1014411571da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0-rc2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7q0dvjtApoJS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import  Dropout, Input\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eryVCI3puK3",
        "colab_type": "code",
        "outputId": "2eb0939f-8115-4b21-f7b7-5da93bbaa81b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "train_path = './gdrive/My Drive/dataSet/train'\n",
        "valid_path = './gdrive/My Drive/dataSet/val'\n",
        "test_path = './gdrive/My Drive/dataSet/test'\n",
        "\n",
        "train_batches = ImageDataGenerator().flow_from_directory(train_path,target_size=(224,224),  batch_size=32)\n",
        "valid_batches = ImageDataGenerator().flow_from_directory(valid_path,target_size=(224,224),  batch_size=32)\n",
        "test_batches = ImageDataGenerator().flow_from_directory(test_path, target_size=(224,224),  batch_size=32)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 188 images belonging to 3 classes.\n",
            "Found 18 images belonging to 3 classes.\n",
            "Found 18 images belonging to 3 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7r4OuUyaVJS",
        "colab_type": "code",
        "outputId": "e0d8dfd5-1ca5-4be5-e98a-fb73e9a71147",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 719
        }
      },
      "source": [
        "vgg16_model = tensorflow.keras.applications.vgg16.VGG16(weights='imagenet', include_top=False, input_tensor=Input(shape=(224,224,3)))\n",
        "for layer in vgg16_model.layers[:-4]:\n",
        "    layer.trainable = False\n",
        "    \n",
        "# Create the model\n",
        "model = Sequential()\n",
        " \n",
        "# Add the vgg convolutional base model\n",
        "model.add(vgg16_model)\n",
        " \n",
        "# Add new layers\n",
        "model.add(Flatten())\n",
        "model.add(Dense(1024, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(3, activation='softmax'))\n",
        " \n",
        "# Show a summary of the model. Check the number of trainable parameters\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tensorflow.keras.optimizers.RMSprop(lr=1e-4),\n",
        "              metrics=['acc'])\n",
        "\n",
        "history = model.fit(train_batches, \n",
        "            epochs=5, \n",
        "            validation_data=valid_batches, \n",
        "            steps_per_epoch=train_batches.samples/train_batches.batch_size,\n",
        "            validation_steps=valid_batches.samples/valid_batches.batch_size,\n",
        "            verbose=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 1s 0us/step\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Model)                (None, 7, 7, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1024)              25691136  \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 3075      \n",
            "=================================================================\n",
            "Total params: 40,408,899\n",
            "Trainable params: 32,773,635\n",
            "Non-trainable params: 7,635,264\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:sample_weight modes were coerced from\n",
            "  ...\n",
            "    to  \n",
            "  ['...']\n",
            "WARNING:tensorflow:sample_weight modes were coerced from\n",
            "  ...\n",
            "    to  \n",
            "  ['...']\n",
            "Train for 5.875 steps, validate for 0.5625 steps\n",
            "Epoch 1/5\n",
            "6/5 [==============================] - 151s 25s/step - loss: 3.8234 - acc: 0.6117 - val_loss: 0.4337 - val_acc: 0.8333\n",
            "Epoch 2/5\n",
            "6/5 [==============================] - 134s 22s/step - loss: 0.2414 - acc: 0.9149 - val_loss: 0.0470 - val_acc: 1.0000\n",
            "Epoch 3/5\n",
            "6/5 [==============================] - 134s 22s/step - loss: 0.1042 - acc: 0.9787 - val_loss: 0.0098 - val_acc: 1.0000\n",
            "Epoch 4/5\n",
            "6/5 [==============================] - 134s 22s/step - loss: 0.0449 - acc: 0.9894 - val_loss: 7.3827e-04 - val_acc: 1.0000\n",
            "Epoch 5/5\n",
            "6/5 [==============================] - 134s 22s/step - loss: 0.0096 - acc: 0.9947 - val_loss: 4.9884e-04 - val_acc: 1.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wgjsVyVkXds7",
        "colab": {}
      },
      "source": [
        "test_imgs, test_labels = next(test_batches)\n",
        "\n",
        "predictions = model.predict(test_imgs)\n",
        "\n",
        "print(predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiOWWA6MKh1G",
        "colab_type": "code",
        "outputId": "b4d292db-166d-4b4a-aa33-629ddf118e74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        }
      },
      "source": [
        "tf.keras.models.save_model(model, \"./gdrive/My Drive/_models/flower/1\")\n",
        "print(\"models written\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "If using Keras pass *_constraint arguments to layers.\n",
            "INFO:tensorflow:Assets written to: ./gdrive/My Drive/_models/flower/1/assets\n",
            "models written\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_Kn11cCsBY6",
        "colab_type": "code",
        "outputId": "e8c4bd6a-d45c-45b7-c19e-9189124bacf9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 577
        }
      },
      "source": [
        "saved_model = tf.keras.models.load_model(\"./gdrive/My Drive/_models/flower/1\")\n",
        "input_shape = (None, 224, 224, 3)\n",
        "saved_model.build(input_shape)\n",
        "saved_model.summary()\n",
        "\n",
        "#imported = tf.saved_model.load(\"/content/gdrive/My Drive/Models/flower/1\")\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
            "\n",
            "Two checkpoint references resolved to different objects (<tensorflow.python.keras.engine.training.Model object at 0x7fc28610add8> and <tensorflow.python.keras.layers.core.Flatten object at 0x7fc2861001d0>).\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
            "\n",
            "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.core.Dense object at 0x7fc2861006d8> and <tensorflow.python.keras.layers.core.Dropout object at 0x7fc286100d30>).\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
            "\n",
            "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.core.Dense object at 0x7fc2861006d8> and <tensorflow.python.keras.layers.core.Flatten object at 0x7fc2861001d0>).\n",
            "WARNING:tensorflow:Inconsistent references when loading the checkpoint into this object graph. Either the Trackable object references in the Python program have changed in an incompatible way, or the checkpoint was generated in an incompatible program.\n",
            "\n",
            "Two checkpoint references resolved to different objects (<tensorflow.python.keras.layers.core.Dense object at 0x7fc286104240> and <tensorflow.python.keras.layers.core.Dropout object at 0x7fc286100d30>).\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "vgg16 (Model)                (None, 7, 7, 512)         14714688  \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 25088)             0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1024)              25691136  \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 3)                 3075      \n",
            "=================================================================\n",
            "Total params: 40,408,899\n",
            "Trainable params: 40,408,899\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2jvfbm6qs8H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_imgs, test_labels = next(test_batches)\n",
        "\n",
        "predictions = saved_model.predict(test_imgs)\n",
        "\n",
        "print(predictions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fZNour1ljjyO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_b64_image(image_bytes, h=224, w=224):\n",
        "    image = tf.io.decode_base64(image_bytes[0])\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    image = tf.image.resize(image, size=[h, w])\n",
        "    #image = (image - 127.5) / 127.5\n",
        "    image = tf.expand_dims(image, axis=0)\n",
        "    return image\n",
        "\n",
        "#image_bytes = Input(shape = (1,),dtype=\"string\")\n",
        "image_bytes = tf.keras.Input(shape=[], batch_size=1, name='b64_image_bytes', dtype=tf.string)\n",
        "preprocessed_image = preprocess_b64_image(image_bytes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8pLxK6OneE9",
        "colab_type": "code",
        "outputId": "688e163c-da1a-4403-d969-f79882e884c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        }
      },
      "source": [
        "predictions = saved_model(preprocessed_image)\n",
        "new_model = tf.keras.Model(image_bytes, predictions)\n",
        "new_model.summary()\n",
        "print('Model Input Shape:', new_model.input_shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "b64_image_bytes (InputLayer) [(1,)]                    0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_strided_slice (T [()]                      0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_DecodeBase64 (Te [()]                      0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_DecodeJpeg (Tens [(None, None, 3)]         0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_ExpandDims (Tens [(1, None, None, 3)]      0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_ResizeBilinear ( [(1, 224, 224, 3)]        0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_Squeeze (TensorF [(224, 224, 3)]           0         \n",
            "_________________________________________________________________\n",
            "tf_op_layer_ExpandDims_1 (Te [(1, 224, 224, 3)]        0         \n",
            "_________________________________________________________________\n",
            "sequential (Sequential)      multiple                  40408899  \n",
            "=================================================================\n",
            "Total params: 40,408,899\n",
            "Trainable params: 40,408,899\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model Input Shape: (1,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Khpj0nO1jwHf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cOm7oxyifh33",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def preprocess_and_decode(img_str, new_shape=[224,224]):\n",
        "    img = tf.io.decode_base64(img_str)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "    img = tf.image.resize(img, new_shape, method=tf.image.ResizeMethod.BILINEAR)\n",
        "    # if you need to squeeze your input range to [0,1] or [-1,1] do it here\n",
        "    return img\n",
        "InputLayer = Input(shape = (1,),dtype=\"string\")\n",
        "OutputLayer = tf.keras.layers.Lambda(lambda img : tf.map_fn(lambda im : preprocess_and_decode(im[0]), img, dtype=\"float32\"))(InputLayer)\n",
        "base64_model = tf.keras.Model(InputLayer,OutputLayer)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKb4RT2n3XmF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "base64_input = base64_model.input\n",
        "final_output = saved_model(base64_model.output)\n",
        "new_model = tf.keras.Model(base64_input,final_output)\n",
        "\n",
        "new_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qzxopp7mL-Oq",
        "colab_type": "code",
        "outputId": "0265ccca-5821-4573-949c-7a9a2f4d985b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tf.keras.models.save_model(new_model, \"./gdrive/My Drive/_models/flower/2\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: ./gdrive/My Drive/_models/flower/2/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxkBOVq361FF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "new_saved_model = tf.keras.models.load_model(\"./gdrive/My Drive/_models/flower/2\")\n",
        "new_saved_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ja4aKPVBcOoa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqQoTYhSF9As",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plots images with labels within jupyter notebook\n",
        "def plots(ims, figsize=(24,12), rows=6, interp=False, titles=None):\n",
        "    if type(ims[0]) is np.ndarray:\n",
        "        ims = np.array(ims).astype(np.uint8)\n",
        "        if (ims.shape[-1] != 3):\n",
        "            ims = ims.transpose((0,2,3,1))\n",
        "    f = plt.figure(figsize=figsize)\n",
        "    cols = len(ims)//rows if len(ims) % 2 == 0 else len(ims)//rows + 1\n",
        "    for i in range(len(ims)):\n",
        "        sp = f.add_subplot(rows, cols, i+1)\n",
        "        sp.axis('Off')\n",
        "        if titles is not None:\n",
        "            sp.set_title(titles[i], fontsize=32)\n",
        "        plt.imshow(ims[i], interpolation=None if interp else 'none')\n",
        "\n",
        "#imgs, labels = next(train_batches)\n",
        "#plots(imgs, titles=labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4TtEkVk4SOY",
        "colab_type": "code",
        "outputId": "08df36f5-f2df-414e-d503-6848ecb91338",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 755
        }
      },
      "source": [
        "!ls -lR ./gdrive/My\\ Drive/models"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "'./gdrive/My Drive/models':\n",
            "total 8\n",
            "drwx------ 3 root root 4096 Nov  5 03:19 flower\n",
            "drwx------ 2 root root 4096 Sep 17 02:35 flowers\n",
            "\n",
            "'./gdrive/My Drive/models/flower':\n",
            "total 285951\n",
            "drwx------ 4 root root      4096 Nov  5 03:19 1\n",
            "-rw------- 1 root root 292808752 Nov  5 03:19 orchid.h5\n",
            "\n",
            "'./gdrive/My Drive/models/flower/1':\n",
            "total 428\n",
            "drwx------ 2 root root   4096 Nov  5 03:19 assets\n",
            "-rw------- 1 root root 429474 Nov  5 03:19 saved_model.pb\n",
            "drwx------ 2 root root   4096 Nov  5 03:19 variables\n",
            "\n",
            "'./gdrive/My Drive/models/flower/1/assets':\n",
            "total 0\n",
            "\n",
            "'./gdrive/My Drive/models/flower/1/variables':\n",
            "total 285887\n",
            "-rw------- 1 root root 292744486 Nov  5 03:19 variables.data-00000-of-00001\n",
            "-rw------- 1 root root      3296 Nov  5 03:19 variables.index\n",
            "\n",
            "'./gdrive/My Drive/models/flowers':\n",
            "total 4\n",
            "drwx------ 2 root root 4096 Sep 17 03:41 00001\n",
            "\n",
            "'./gdrive/My Drive/models/flowers/00001':\n",
            "total 430\n",
            "drwx------ 2 root root   4096 Sep 17 03:41 assets\n",
            "-rw------- 1 root root 431974 Sep 17 03:41 saved_model.pb\n",
            "drwx------ 2 root root   4096 Sep 17 03:41 variables\n",
            "\n",
            "'./gdrive/My Drive/models/flowers/00001/assets':\n",
            "total 0\n",
            "\n",
            "'./gdrive/My Drive/models/flowers/00001/variables':\n",
            "total 285888\n",
            "-rw------- 1 root root 292744954 Sep 17 03:41 variables.data-00000-of-00001\n",
            "-rw------- 1 root root      3276 Sep 17 03:41 variables.index\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVaPdiWnl5LM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-wKJt7Kxk_wj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!ls -lR ./gdrive/My\\ Drive/_models\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BudCDVhr6j9m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!saved_model_cli show --dir ./gdrive/My\\ Drive/_models/flower/2 --all"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_s0zo6C6n3bl",
        "colab_type": "code",
        "outputId": "52e2ab0e-ed0b-4bad-80d4-75def8e56445",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras\n",
        "\n",
        "\n",
        "image_bytes = tf.keras.Input(shape=[], batch_size=1, name='b64_image_bytes', dtype=tf.string)\n",
        "\n",
        "print(image_bytes)\n",
        "print(image_bytes.shape)\n",
        "\n",
        "print(image_bytes[0])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"b64_image_bytes_1:0\", shape=(1,), dtype=string)\n",
            "(1,)\n",
            "Tensor(\"strided_slice:0\", shape=(), dtype=string)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}